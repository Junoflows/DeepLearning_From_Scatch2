{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rrwtFWQefdPJ2DiC-rJMmUnoi3SbeS1A",
      "authorship_tag": "ABX9TyPApCRJ6KOPU8osuASu/Nmz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junoflows/Deeplearning_From_Scatch2/blob/main/Chapter_2_%EC%9E%90%EC%97%B0%EC%96%B4%EC%99%80_%EB%8B%A8%EC%96%B4%EC%9D%98_%EB%B6%84%EC%82%B0_%ED%91%9C%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2 자연어와 단어의 분산 표현"
      ],
      "metadata": {
        "id": "MAAb-wwZJXdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 자연어 처리의 본질적 문제는 컴퓨터가 우리의 말을 이해하게 만드는 것이다.\n",
        "+ 이에 대해 어떠한 방법이 있는지를 살펴보고 고전적인 기법을 자세히 살펴보자."
      ],
      "metadata": {
        "id": "CxO460OcJaII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 자연어 처리란\n"
      ],
      "metadata": {
        "id": "E9lN9XKRK1EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 한국어, 영어 등 평소에 쓰는 말을 자연어라고 한다.\n",
        "+ 자연어 처리(NLP)는 자연어를 처리하는 분야로, 우리의 말을 컴퓨터에게 이해시키기 위한 기술이다.\n",
        "+ 컴퓨터가 이해할 수 있는 언어는 기계어로 모든 코드의 의미를 고유하게 해석할 수 있도록 문법이 정의되어 있고 이 정해진 규칙에 따라 코드를 해석한다."
      ],
      "metadata": {
        "id": "LBKiCNqkK_OT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 일반적인 프로그래밍 언어는 기계적이고 고정되어 있는 딱딱한 언어이다.\n",
        "+ 반면 자연어는 부드러운 언어인데 이는 같은 의미의 문장도 여러 형태로 표현할 수 있거나,  \n",
        "문장의 뜻이 애매하거나, 의미가 형태가 유연하게 바뀐다는 뜻이다."
      ],
      "metadata": {
        "id": "nTmztlE8LlYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 컴퓨터에게 자연어를 이해시키기는 어려운 일이지만 해낼 수 있다면 사람에게 도움되는 일을 컴퓨터에게 시킬 수 있을 것이다."
      ],
      "metadata": {
        "id": "lw5FIbeEMLoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 단어의 의미"
      ],
      "metadata": {
        "id": "lXCppYVFMq4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 우리의 말은 문자로 구성되며 의미는 단어로 구성된다. 즉 단어는 의미의 최소단위이다.\n",
        "+ 자연어를 컴퓨터에게 이해시키는데는 단어의 의미를 이해시키는 것이 중요하다.\n",
        "+ 단어의 의미를 잘 파악하는 표현 방법에 대해 살펴보자.\n",
        "+ 구체적으로 아래 세 가지 기법을 살펴보자."
      ],
      "metadata": {
        "id": "8Ny46Rg3NfkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> + 시소러스를 활용한 기법\n",
        "+ 통계 기반 기법\n",
        "+ 추론 기밥 기법(word2vec)"
      ],
      "metadata": {
        "id": "wg_nD4K1OehC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 시소러스"
      ],
      "metadata": {
        "id": "dXyrKe2KOvES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 단어의 의미를 나타내는 방법으로 사람이 직접 단어의 의미를 정의하는 방식이 있다.\n",
        "+ 하나의 방법으로 표준국어대사전처럼 각 단어에 그 위미를 설명해 넣을 수 있다.\n",
        "+ 자연어 처리의 역사를 보면 시소러스 형태의 사전을 사용했다.\n"
      ],
      "metadata": {
        "id": "P3nlj2CtOxq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 시소러스란 유의어 사전으로 뜻이 같은 단어(동의어)나 뜻이 비슷한 단어(유의어)가 한 그룹으로 분류되어 있다."
      ],
      "metadata": {
        "id": "Mte0inHpPL8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1DTuuYwj_2AgcrTuyKBd02QbCO2hYk3tW' width = 550/><br>"
      ],
      "metadata": {
        "id": "ap_V5CgRP3dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 자연어 처리에 이용되는 시소러스에서 단어 사이의 '상위와 하위' 또는 '전체와 부분' 등 더 세세한 관계까지 정의해둔 경우도 있다.\n",
        "+ 아래 그림처럼 각 단어의 관계를 그래프 구조로 정의한다."
      ],
      "metadata": {
        "id": "5fVw8ancQmye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1ewbu-SWstGEfDFdZ-m9aG5fOPWJIpLpP' width= 550/><br>"
      ],
      "metadata": {
        "id": "zbQMhSFnRBvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ car의 상위 개념으로 motor vehicle이라는 단어가 존재한다.\n",
        "+ car의 하위 개념으로 SUV, compact, hatch-back 등 더 구체적인 차종이 있다.\n",
        "+ 이처럼 모든 단어에 대한 유의어 집합을 만들고 관계를 그래프로 표현하여 단어 사이의 연결을 정의할 수 있다.\n",
        "+ 이 단어 네트워크를 이용하여 컴퓨터에게 단어 사이의 관계를 가르칠 수 있다."
      ],
      "metadata": {
        "id": "EG_pyMXdRM2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 WordNet"
      ],
      "metadata": {
        "id": "sSd656SoR6fS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 자연어 처리 분야에서 가장 유명한 시소러스는 __WordNet__이다.\n",
        "+ WordNet은 1985년부터 구축되어 지금까지 많은 연구와 다양한 자연어 처리 어플리케이션으로 활용된다.\n",
        "+ 이를 사용하면 유의어를 얻거나 단어 네트워크를 이용할 수 있고 단어 사이의 유사도를 구할 수 있다.\n",
        "+ 여기서는 자세히 다루지는 않겠다."
      ],
      "metadata": {
        "id": "OwejyvI9R8cR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 시소러스의 문제점"
      ],
      "metadata": {
        "id": "dMJoYbO_SP4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 시소러스에는 수많은 단어에 대한 동의어와 계층 구조 등의 관계가 정의되어 있다.\n",
        "+ 이 지식을 이용하면 단어의 의미를 컴퓨터에 전달할 수 있다.\n",
        "+ 하지만 수작업으로 레이블링하는 방식에는 큰 문제점들이 존재한다."
      ],
      "metadata": {
        "id": "C1bBcEIsSfF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__시대 변화에 대응하기 어렵다.__\n",
        "\n",
        "때때로 새로운 단어가 생기고 옛말은 잊혀지고 시대에 따라 의미가 변하기도 한다. 이런 단어의 변화에 대응하려면 시소러스를 사람이 수작업으로 끊임없이 갱신해야 한다.\n",
        "<br/><br/>\n",
        "__사람을 쓰는 비용이 크다.__\n",
        "\n",
        "시소러스를 만드는 데 엄청난 인적 비용이 발생한다. 영어를 예로 들면 현존하는 영단어 수는 1000만개가 넘는다고 하는데 이 방대한 단어들에 대해 단어 사이의 관계를 정의해줘야한다.\n",
        "<br/><br/>\n",
        "__단어의 미묘한 차이를 표현할 수 없다.__\n",
        "\n",
        "예를들어 빈티지와 레트로는 의미는 같지만 용법은 다르다. 시소러스에서는 이러한 미묘한 차이를 표현할 수 없다."
      ],
      "metadata": {
        "id": "kJR76DNmSsN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이런 문제를 피하기 위해 통계 기반 기법과 추론 기반 기법을 알아보자."
      ],
      "metadata": {
        "id": "LWteb4uoTkX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 통계 기반 기법"
      ],
      "metadata": {
        "id": "2BxTXEqaTo09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 통계 기반 기법을 살펴보면서 말뭉치를 이용한다.\n",
        "+ 말뭉치란 자연어 처리 연구나 애플리케이션을 염두에 두고 수집된 대량의 텍스트 데이터를 말한다.\n",
        "+ 말뭉치에는 자연어에 대한 사람의 지식이 충분히 담겨 있다고 볼 수 있다.\n",
        "+ 통계 기반 기법의 목표는 사람의 지식으로 가득한 말뭉치에서 자동으로, 효율적으로 핵심을 추출하는 것이다."
      ],
      "metadata": {
        "id": "OiGatttKTu0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 파이썬으로 말뭉치 전처리하기"
      ],
      "metadata": {
        "id": "Y757SXPoUIdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 자연어 처리에는 다양한 말뭉치가 사용되는데 위키백과, 구글 뉴스 등의 텍스트 데이터가 예이다.\n",
        "+ 우선 문장 하나로 이뤄진 단순한 텍스트를 사용하고 이 후 실용적인 말뭉치를 다루자.\n",
        "+ 파이썬에서 텍스트 데이터를 단어로 분할하고 분할한 단어를 단어 ID 목록으로 변환해보자."
      ],
      "metadata": {
        "id": "TF-OIFGuUapj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN2uvkaSJR5G"
      },
      "outputs": [],
      "source": [
        "text = 'You say goodbye and I say hello.'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 text를 단어 단위로 분할하자."
      ],
      "metadata": {
        "id": "uRWYbX5ZU44b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower()\n",
        "text = text.replace('.',' .')\n",
        "print(text)\n",
        "words = text.split(' ')\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-gBnvDnU3Zj",
        "outputId": "8fee41f4-13f0-4cb4-dd47-6cee0b3b75af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you say goodbye and i say hello .\n",
            "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ lower()로 소문자로 변환한다.\n",
        "+ split(' ')로 공백을 기준으로 분할하는데 마침표를 고려해 마침표 앞에 공백을 삽입하고 분할을 수행한다.\n",
        "+ 이제 단어에 ID를 부여하고, ID의 리스트로 이용할 수 있도록 파이썬의 딕셔너리를 이용하여 단어 ID와 단어를 짝지어주자."
      ],
      "metadata": {
        "id": "bWseh4diVZ3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_id = {}\n",
        "id_to_word = {}\n",
        "\n",
        "for word in words:\n",
        "  if word not in word_to_id:\n",
        "    new_id = len(word_to_id)\n",
        "    word_to_id[word] = new_id\n",
        "    id_to_word[new_id] = word"
      ],
      "metadata": {
        "id": "g2PDFYdOVLKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 단어 ID에서 단어로의 변환은 id_to_word가 담당하고  \n",
        "단어에서 단어 ID로의 변환은 word_to_id가 담당한다.\n",
        "+ 단어가 word_to_id에 들어있지 않으면 word_to_id와 id_to_word 각각에 새로운 ID와 단어를 추가한다.\n",
        "+ 또한 추가 시점의 딕셔너리 길이가 새로운 단어이 ID로 설정되기 때문에 단어 ID는 0,1,2, ...으로 증가한다.\n",
        "+ 실제 어떤 내용이 담겼는지 살펴보자."
      ],
      "metadata": {
        "id": "lWoezOriYMF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(id_to_word)\n",
        "print(word_to_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5oPI0mIX_NO",
        "outputId": "0d7f5569-fd8d-4ca8-b237-8857da377861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
            "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 딕셔너리를 사용해 단어를 가지고 단어 ID를 검색하거나 단어 ID를 가지고 단어를 검색할 수 있다."
      ],
      "metadata": {
        "id": "aLK7ydZWZMR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(id_to_word[1])\n",
        "print(word_to_id['hello'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wde-HulGYxzt",
        "outputId": "09fddf3b-934a-46d6-8389-6b729b0f4ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "say\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 단어 목록을 단어 ID 목록으로 변경해보자."
      ],
      "metadata": {
        "id": "tELgPBpLb9fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "corpus = [word_to_id[w] for w in words]\n",
        "corpus = np.array(corpus)\n",
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FneA3sNWZU8F",
        "outputId": "7d424269-9789-4d28-b3be-22f216674e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 1 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 처리를 한 데 모아서 preprocess() 함수로 구현해보자."
      ],
      "metadata": {
        "id": "rd855e_gcPTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('.',' .')\n",
        "  words = text.split(' ')\n",
        "\n",
        "  word_to_id = {}\n",
        "  id_to_word = {}\n",
        "\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "      id_to_word[new_id] = word\n",
        "\n",
        "  corpus = np.array([word_to_id[w] for w in words])\n",
        "\n",
        "  return corpus, word_to_id, id_to_word"
      ],
      "metadata": {
        "id": "AHpBQyeZcIRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)"
      ],
      "metadata": {
        "id": "ESsT2tDwcpZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이것으로 말뭉치 전처리가 끝났다.\n",
        "+ 이를 사용해 단어의 의미를 추출하는 방법으로 통계 기반 기법을 살펴보자."
      ],
      "metadata": {
        "id": "M4peaesgc6g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 단어의 분산 표현"
      ],
      "metadata": {
        "id": "5jTP87_IdCdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 색은 RGB라는 세 가지 성분의 비율을 3차원 벡터로 표현할 수 있다.\n",
        "+ 단어도 벡터로 표현할 수 있을까?\n",
        "+ 단어의 의미를 정확하게 파악하는 벡터 표현을 자연어 처리 분야에서 단어의 분산 표현이라고 한다."
      ],
      "metadata": {
        "id": "L2fw0X8xdrMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__NOTE__ <br/>\n",
        "단어의 분산 표현은 단어를 고정 길이의 밀집벡터로 표현한다. 밀집벡터는 대부분의 원소가 0이 아닌 실수인 벡터를 의미한다."
      ],
      "metadata": {
        "id": "wUwPvgE_eOTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.3 분포 가설"
      ],
      "metadata": {
        "id": "ZPY4PWvCeY6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 단어를 벡터로 표현하는 기법에서 중요한 아이디어는  \n",
        "단어의 의미는 주변 단어에 의해 형성된다는 것으로 이를 분포 가설이라고 한다.\n",
        "+ 분포 가설의 요점은 단어 자체에는 의미가 없고, 그 단어가 사용된 맥락이 의미를 형성한다는 것이다.\n",
        "+ 예를들어 'I drink beer'과 'We drink wine'처럼 drink 주변에는 음료가 등장하기 쉬울 것이다.\n",
        "+ I guzzle beer'과 'We guzzle wine'에서 보면 'guzzle'과 'drink'가 같은 맥락에서 사용됨을 알 수 있다.\n",
        "+ 이 두 단어가 가까운 의미의 단어라는 것도 알 수 있다. (guzzle : 폭음하다)"
      ],
      "metadata": {
        "id": "wxu2r7dTekKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 맥락이라 하면 주변에 놓인 단어를 가리킨다.\n",
        "+ 아래 그림에서 좌우의 각 두 단어씩이 맥락에 해당한다."
      ],
      "metadata": {
        "id": "pt0bS0YEf1iC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1_RK0n4cxQ7wBJ1r_tjw8fib0z-rZNLyc' width = 550/><br>"
      ],
      "metadata": {
        "id": "mD4CkQpCgEar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 맥락이란 특정 단어를 중심에 둔 주변 단어를 말한다.\n",
        "+ 맥락의 크기를 원도우 크기(window size)라고 한다.\n",
        "+ window size가 1이면 좌우 한 단어씩, 2이면 좌우 두 단어씩이 맥락에 포함된다."
      ],
      "metadata": {
        "id": "IE7f57LVgHD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.4 동시발생 행렬"
      ],
      "metadata": {
        "id": "ecLvaPfBgSxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 분포 가설에 기초해 단어를 벡터로 나타내는 방법을 생각해보자.\n",
        "+ 어떤 단어에 주목했을 때 그 주변에 어떤 단어가 몇 번 등장하는지를 세어 집계하는 방법이 있다.\n",
        "+ 이를 통계 기반 기법이라 한다.\n",
        "+ 통계 기반 기법을 살펴보자. preprocess() 함수를 사용해 전처리부터 시작한다."
      ],
      "metadata": {
        "id": "aYIzG2ZPgUQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep-learning-from-scratch-2-master/')\n",
        "import numpy as np\n",
        "from common.util import preprocess\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "print(corpus)\n",
        "print(id_to_word)"
      ],
      "metadata": {
        "id": "4WrNxVzJd7N1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364740db-313d-45f0-baac-f82e6d6b9893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 결과를 보면 단어 수가 총 7개 임을 알 수 있다.\n",
        "+ 각 단어의 맥락에 해당하는 단어의 빈도를 세어보자. window size는 1로 하고 단어 ID가 0인 'you'부터 시작하자."
      ],
      "metadata": {
        "id": "ItUZB4irvqFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1l77qcJKpS036a8CE1wticew34O-wt-aY' width = 550/>"
      ],
      "metadata": {
        "id": "Bkb-AzzLwCA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위에서 알 수 있듯, 단어 'you'의 맥락은 'say'라는 단어 하나뿐이다. 이를 표로 정리하면 다음과 같다."
      ],
      "metadata": {
        "id": "VYsN3gsmxCdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1cUm5AUz6ejU48YUz9ULfbPYAK1gfIHpa' width =550 /><br>"
      ],
      "metadata": {
        "id": "upNfZ9D1xT7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 'you'의 맥락으로써 동시에 발생하는 단언의 빈도를 나타낸 표이다.\n",
        "+ 이를 바탕으로 'you'라는 단어를 [0,1,0,0,0,0,0]이라는 벡터로 표현할 수 있다.\n",
        "+ 계속해서 ID가 1인 'say' 대해 같은 작업을 수행한다."
      ],
      "metadata": {
        "id": "Qk1mpzWUxWrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=11MKRRLuJfuyjtnQKiKO0d7NAeFVxgRXL' width = 550/><br>"
      ],
      "metadata": {
        "id": "qC-Ffu6oxqA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 결과로부터는 'say'라는 단어를 벡터 [1,0,1,0,1,1,0]으로 표현할 수 있다.\n",
        "+ 위 작업을 모든 단어에 대해 수행하자."
      ],
      "metadata": {
        "id": "LmKpumFtx0UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=10cjCZKcsel63X2LTuCMUKOWHTOlCgCaJ' width = 550 /><br>"
      ],
      "metadata": {
        "id": "dHhCrUfgyBFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 모든 단어에 대해 동시발생하는 단어를 표에 정리한 것이다.\n",
        "+ 표의 각 행은 해당 언어를 표현한 벡터가 된다.\n",
        "+ 이 표를 행렬의 형태를 띤다고 해서 동시발생 행렬이라고 한다.\n",
        "+ 이를 파이썬으로 구현해보자."
      ],
      "metadata": {
        "id": "7F_40R1QFoar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = np.array([[0,1,0,0,0,0,0],\n",
        "              [1,0,1,0,1,1,0],\n",
        "              [0,1,0,1,0,0,0],\n",
        "              [0,0,1,0,1,0,0],\n",
        "              [0,1,0,1,0,0,0],\n",
        "              [0,1,0,0,0,0,1],\n",
        "              [0,0,0,0,0,1,0],], dtype = np.int32)"
      ],
      "metadata": {
        "id": "6MowxK9dumHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(C[0])\n",
        "print(C[4])\n",
        "print(C[word_to_id['goodbye']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QajAZobHGPq9",
        "outputId": "d0c53f46-ff59-492e-c12e-ec28ca74a590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 0 0]\n",
            "[0 1 0 1 0 0 0]\n",
            "[0 1 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이처럼 동시발생 행렬을 활용하면 단어를 벡터로 나타낼 수 있다.\n",
        "+ 위 방식은 동시발생 행렬을 수동으로 만들었지만 자동화할 수 있다.\n",
        "+ 말뭉치로부터 동시발생 행렬을 만들어주는 함수를 구현해보자.\n",
        "+ 함수 이름은 creat_co_matrix(corpus, vocab_size, window_size = 1)로 하자.  \n",
        "인수는 차례로 단어ID의 리스트, 어휘 수, 윈도우 크기를 나타낸다."
      ],
      "metadata": {
        "id": "_7NdR6ZcG1yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
        "    corpus_size = len(corpus)\n",
        "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "\n",
        "    for idx, word_id in enumerate(corpus):\n",
        "        for i in range(1, window_size + 1):\n",
        "            left_idx = idx - i\n",
        "            right_idx = idx + i\n",
        "\n",
        "            if left_idx >= 0:\n",
        "                left_word_id = corpus[left_idx]\n",
        "                co_matrix[word_id, left_word_id] += 1\n",
        "\n",
        "            if right_idx < corpus_size:\n",
        "                right_word_id = corpus[right_idx]\n",
        "                co_matrix[word_id, right_word_id] += 1\n",
        "\n",
        "    return co_matrix"
      ],
      "metadata": {
        "id": "8svr4xsyHRR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 먼저 co_matrix를 0으로 채워진 2차원 배열로 초기화한다.\n",
        "+ 말뭉치의 모든 단어 각각에 대해 윈도우에 포함된 주변 단어를 센다.\n",
        "+ 이때 말뭉치의 왼쪽 끝과 오른쪽 끝 경계를 벗어나지 않는지 확인한다.\n",
        "+ 이 함수는 말뭉치가 커지더라도 자동으로 동시발생 행렬을 만들어준다."
      ],
      "metadata": {
        "id": "gpPRi2npI8UX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.5 벡터 간 유사도"
      ],
      "metadata": {
        "id": "QQP1unytJLVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 벡터 사이의 유사도를 측정하는 방법을 살펴보자.\n",
        "+ 벡터의 내적이나 유클리드 거리 등 많은 방법이 있지만 주로 코사인 유사도를 이용한다.\n",
        "+ 두 벡터 $x=(x_1,x_2,...,x_n)$, $y=(y_1,y_2,...,y_n)$가 있다면 코사인 유사도는 다음 식으로 정의된다."
      ],
      "metadata": {
        "id": "41ahPC4uKWus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1PY6d08TNcydYI8WdE6i0Q0XPXqeS6VUL' width = 550/><br>"
      ],
      "metadata": {
        "id": "DgM40sReLSKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 식의 분자에는 벡터의 내적이, 분모에는 각 벡터의 노름이 나온다.\n",
        "+ 노름은 벡터의 크기를 나타낸 것이다.\n",
        "+ 위 식의 핵심은 벡터를 정규화하고 내적을 구하는 것이다."
      ],
      "metadata": {
        "id": "VtZAtNuxLVR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__NOTE__<br/>\n",
        "코사인 유사도를 직관적으로 보면 두 벡터가 가리키는 방향이 얼마나 비슷한가이다.  \n",
        "두 벡터의 방향이 완전히 같으면 1이 되고 반대면 -1이 된다."
      ],
      "metadata": {
        "id": "FW-FAGq7Lg-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 코사인 유사도를 함수로 구현해보자."
      ],
      "metadata": {
        "id": "577y7R5uLtAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similarity(x, y):\n",
        "    nx = x / (np.sqrt(np.sum(x ** 2))) # x의 정규화\n",
        "    ny = y / (np.sqrt(np.sum(y ** 2))) # y의 정규화\n",
        "    return np.dot(nx, ny)"
      ],
      "metadata": {
        "id": "-C9dPr8HNGfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 함수는 벡터 x와 y를 정규화 후 벡터의 내적을 구했다.\n",
        "+ 이 구현에는 문제가 있는데 인수로 0벡터가 들어오면 0으로 나누는 오류가 발생한다.\n",
        "+ 이를 해결하기 위해서 분모에 작은 값을 더해주면 된다."
      ],
      "metadata": {
        "id": "pR6yvHflNNya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similarity(x, y, eps=1e-8):\n",
        "    nx = x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
        "    ny = y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
        "    return np.dot(nx, ny)"
      ],
      "metadata": {
        "id": "JIXEq2EdJK1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__NOTE__<br/>\n",
        "1e-8의 작은 값을 사용하는 이유는 이 정도의 작은 값은 파이썬 부동 소수점 계산 시 반올림되어 최종 계산 결과에 영향을 주지 않는다.  \n",
        "하지만 벡터의 노름이 0일 때는 이 작은 값이 유지되어 0으로 나누는 오류를 막아준다."
      ],
      "metadata": {
        "id": "ua0Rp88CL5HY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 함수를 이용해 단어 벡터의 유사도를 구현할 수 있다.  \n",
        "다음은 you와 i의 유사도를 구하는 코드이다."
      ],
      "metadata": {
        "id": "9RgWoJ6iMXjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep-learning-from-scratch-2-master/')\n",
        "from common.util import preprocess, create_co_matrix, cos_similarity\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "\n",
        "c0 = C[word_to_id['you']]  # \"you\"의 단어 벡터\n",
        "c1 = C[word_to_id['i']]    # \"i\"의 단어 벡터\n",
        "print(cos_similarity(c0, c1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQnWh0XFMVS_",
        "outputId": "be0e5442-f6e5-4ade-8b66-9f88bf58cd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7071067691154799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 실행 결과 you와 i의 코사인 유사도는 0.70.. 으로 나왔다.\n",
        "+ 코사인 유사도 값은 -1에서 1 사이이므로 비교적 높은 유사도라고 할 수 있다."
      ],
      "metadata": {
        "id": "C7I8Wt_jNh72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.6 유사 단어의 랭킹 표시"
      ],
      "metadata": {
        "id": "S0FoY4RkNuZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 어떤 단어가 검색어로 주어지면 그 검색어와 비슷한 단어를 유사도 순으로 출력하는 함수를 구현해보자.\n"
      ],
      "metadata": {
        "id": "b7yNcEomNwnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수명\n",
        "```\n",
        "most_similar(query, word_to_id, id_to_word, word_matrix, top = 5)\n",
        "```\n",
        "|인수명|설명|\n",
        "|------|---|\n",
        "|query|검색어(단어)|\n",
        "|word_to_id|단어에서 단어ID로의 딕셔너리|\n",
        "|id_to_word|단어 ID에서 단어로의 딕셔너리|\n",
        "|word_matrix|단어 벡터들을 모은 행렬, 각 행에 대응하는 단어의 벡터가 저장되어 있다고 가정한다.|\n",
        "|top|상위 몇 개까지 출력할 지 설정|\n",
        "\n",
        "most_sililar()함수의 구현은 다음과 같다."
      ],
      "metadata": {
        "id": "e3wOsL8fOCh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
        "    # 1. 검색어를 꺼낸다\n",
        "    if query not in word_to_id:\n",
        "        print('%s(을)를 찾을 수 없습니다.' % query)\n",
        "        return\n",
        "\n",
        "    print('\\n[query] ' + query)\n",
        "    query_id = word_to_id[query]\n",
        "    query_vec = word_matrix[query_id]\n",
        "\n",
        "    # 2. 코사인 유사도 계산\n",
        "    vocab_size = len(id_to_word)\n",
        "\n",
        "    similarity = np.zeros(vocab_size)\n",
        "    for i in range(vocab_size):\n",
        "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
        "\n",
        "    # 3. 코사인 유사도를 기준으로 내림차순으로 출력\n",
        "    count = 0\n",
        "    for i in (-1 * similarity).argsort():\n",
        "        if id_to_word[i] == query:\n",
        "            continue\n",
        "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
        "\n",
        "        count += 1\n",
        "        if count >= top:\n",
        "            return"
      ],
      "metadata": {
        "id": "PWHdYCLvO8uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 코드는 다음 순서로 동작한다.\n",
        "1. 검색의어 단어 벡터를 꺼낸다.\n",
        "2. 검색어의 단어 벡터와 다른 모든 단어 벡터와의 코사인 유사도를 각각 구한다.\n",
        "3. 계산한 코사인 유사도 결과를 기준으로 값이 높은 순서대로 출력한다."
      ],
      "metadata": {
        "id": "-7E5XuLfW3Mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 3.코드에 대해 설명을 추가하면 similarity 배열에 담긴 원소의 인덱스를 내림차순으로 정렬한 후 상위 원소들을 출력한다.\n",
        "+ 이때 argsort()는 배열 인덱스의 정렬을 바꾸는데 넘파이 배열의 원소를 오름차순으로 정렬한다.\n",
        "+ argsort()에 대한 예를 살펴보자."
      ],
      "metadata": {
        "id": "Hn_ZyFPrXL42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([100, -20, 2])\n",
        "x.argsort()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At52H5ctW48d",
        "outputId": "3544e3c8-eaa5-4e95-a4e5-06ec6045303a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이때 반환된 배열의 원소들은 원래 배열의 인덱스에 해당한다.\n",
        "+ 우리의 목적은 단어의 유사도가 큰 순서대로 정렬하는 것으로 내림차순 정렬을 해야한다.\n",
        "+ 내림차순으로 정렬하려면 각 원소에 마이너스를 곱한 후 argsort()를 실행한다."
      ],
      "metadata": {
        "id": "t5ESV8rAX3i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(-x).argsort()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxHKGl1FXuql",
        "outputId": "e9f37dd7-7b91-459d-f5ae-a8b3078f0c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ argsort()를 사용하면 단어의 유사도가 높은 순서로 출력할 수 있다.\n",
        "+ 이상이 most_similar() 함수의 구현이고 이 함수를 사용해보자."
      ],
      "metadata": {
        "id": "i72sjPtAYLPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep-learning-from-scratch-2-master/')\n",
        "from common.util import preprocess, create_co_matrix, most_similar\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "\n",
        "most_similar('you', word_to_id, id_to_word, C, top=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR_KSBS3YKTO",
        "outputId": "3bb36745-4ab7-43be-d4ed-4ea073e7e0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[query] you\n",
            " goodbye: 0.7071067691154799\n",
            " i: 0.7071067691154799\n",
            " hello: 0.7071067691154799\n",
            " say: 0.0\n",
            " and: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 결과는 검색어 you와 유사한 단어를 상위 5개만 출력한 것이다.\n",
        "+ 코사인 유사도는 해당 단어 오른쪽 값에 해당하는데 결과를 보면 you에 가장 가까운 단어는 goodbye, i, hello이다.\n",
        "+ you와 i가 비슷하다는 것은 납득이 되지만 goodbye나 hello의 코사인 유사도가 높다는 것은 우리의 직관과는 거리가 멀다.\n",
        "+ 이는 말뭉치의 크기가 너무 작은 것이 원인이며, 나중에 더 큰 말뭉치를 사용하여 똑같은 실험을 해볼 때 확인해보자."
      ],
      "metadata": {
        "id": "EkmbxREQYmfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 통계 기반 기법 개선하기"
      ],
      "metadata": {
        "id": "s1ivajHDZKQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 앞서 동시발생 행렬을 만들었는데 아직 개선할 점이 남아있다.\n",
        "+ 개선 작업을 해보고 더 실용적인 말뭉치를 사용하여 단어의 분산을 얻어보자."
      ],
      "metadata": {
        "id": "g4sGCfw1ZdsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.1 상호정보량"
      ],
      "metadata": {
        "id": "6Z8atQ5NZrqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 앞서 동시발생 행렬의 원소는 두 단어가 동시에 발생한 횟수를 나타낸다.\n",
        "+ 발생 횟수라는 것은 좋은 특징이 아닌데, 고빈도 단어에서 이유를 살펴보자.\n",
        "+ 예를들어 말뭉치에서 the, car, drive의 동시발생을 살펴보자.\n",
        "+ the와 car의 발생빈도가 car, drive의 발생빈도보다 높지만 car drive가 관련성을 더 높다.\n",
        "+ 발생빈도 관점으로만 보면 the와 car이 관련성이 높다고 평가될 것이다."
      ],
      "metadata": {
        "id": "46zXGILRZ3Y0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 문제를 해결하기 위해 점별 상호정보량(PMI)이라는 척도를 사용한다.\n",
        "+ PMI는 확률 변수 x와 y에 대해 다음 식으로 정의된다."
      ],
      "metadata": {
        "id": "5sF1vHPCaekl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1iIgoOxxS_4Nl2XTGc9Huy6swLi30OzRz' width = 550 /><br>"
      ],
      "metadata": {
        "id": "8ZKue1YTavWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ P(x)는 x가 일어날 확률, P(y)는 y가 일어날 확률, P(x,y)는 x,y가 동시에 일어날 확률이다.\n",
        "+ 이 값이 클수록 관련성이 높다는 뜻이다."
      ],
      "metadata": {
        "id": "KnUhLAdea4UA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이 식을 자연어 예에 적용하면 P(x)는 단어 x가 말뭉치에 등장할 확률을 가리킨다.\n",
        "+ 10,000개 단어의 말뭉치에서 the가 100번 등장하면 $P(\"the\") = \\frac{100}{10000} = 0.01$이 된다.\n",
        "+ P(x,y)는 단어 x,y가 동시에 발생할 확률이므로 the와 car이 10번 동시에 발생했다면 $P(\"the\", \"car\") = \\frac{10}{10000} = 0.001$이 된다."
      ],
      "metadata": {
        "id": "lQwVn240bEeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 동시발생 행렬을 사용하여 위 식을 다시 써보자\n",
        "+ C는 동시발생 행렬, C(x,y)는 단어 x,y가 동시발생하는 횟수, C(x), C(y)는 각각 단어 x,y의 등장 횟수이다.\n",
        "+ 말뭉치에 포함된 단어가 N개라고 하면 다음과 같이 식을 쓸 수 있다."
      ],
      "metadata": {
        "id": "6W26D-HGcE4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1ObRL_fzBTKk8TO8DVPRma9NeMi3crq5W' width = 550/><br>"
      ],
      "metadata": {
        "id": "WHmXiUdqcxpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위에 따라 동시발생 행렬로부터 PMI를 구할 수 있다.\n",
        "+ 말뭉치 단어 수를 10,000이라 하고, the, car, drive가 각각 1,000번, 20번, 10번 등장했다고 하자.\n",
        "+ the, car의 동시발생 횟수는 10회, car, drive의 동시발생 횟수는 5회라고 하자\n",
        "+ 동시발생 횟수 관점에서는 car은 the와 관련이 더 깊다고 나오는데 PMI 관점에서는 어떨지 보자."
      ],
      "metadata": {
        "id": "10X95wQaczyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1kB1uBZV2OVIV0Y-2xUPnnRw4P5vcNdjJ' width =550/><br>\n",
        "<img src='http://drive.google.com/uc?export=view&id=1-0FVyF5qI-gT0tzUcMN2g0PlWZab2yyF' width = 550/><br>"
      ],
      "metadata": {
        "id": "Z8PVTiT_dZoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ PMI를 이용하면 car은 drive와의 관련성이 강해진다.\n",
        "+ 이는 단독으로 출현하는 횟수가 고려되었기 때문이고 the가 자주 출현했으므로 PMI점수가 낮아진 것이다."
      ],
      "metadata": {
        "id": "K9Uy3_0aeBd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ PMI에도 한 가지 문제가 있는데 동시발생 횟수가 0이면 $log_2 0 = -∞$가 된다는 것이다.\n",
        "+ 이 문제를 피하기 위해 실제 구현할 때는 양의 상호정보량(PPMI)를 사용한다."
      ],
      "metadata": {
        "id": "Zx60GnDTeOin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1vKjmwdnmP4KXt2S_qVAfAi3TUp8HqY2G' width =550/><br>"
      ],
      "metadata": {
        "id": "fl0aeeToesmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ PMI가 음수일 때는 0으로 취급하므로 단어 사이의 관련성을 0이상의 실수로 나타낼 수 있다.\n",
        "+ 동시발생 행렬을 PPMI 행렬로 변환하는 함수를 구현해보자."
      ],
      "metadata": {
        "id": "wkzFd8mme2GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ppmi(C, verbose=False, eps = 1e-8):\n",
        "    M = np.zeros_like(C, dtype=np.float32)\n",
        "    N = np.sum(C)\n",
        "    S = np.sum(C, axis=0)\n",
        "    total = C.shape[0] * C.shape[1]\n",
        "    cnt = 0\n",
        "\n",
        "    for i in range(C.shape[0]):\n",
        "        for j in range(C.shape[1]):\n",
        "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
        "            M[i, j] = max(0, pmi)\n",
        "\n",
        "            if verbose:\n",
        "                cnt += 1\n",
        "                if cnt % (total//100 + 1) == 0:\n",
        "                    print('%.1f%% 완료' % (100*cnt/total))\n",
        "    return M"
      ],
      "metadata": {
        "id": "UASma8X0Yj4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 인수 C는 동시발생행렬, verbose는 진행상황 출력 여부를 결정하는 플레그이다.\n",
        "+ 큰 말뭉치를 다룰 때 verbose = True로 설정하면 중간 진행 상황을 알려준다.\n",
        "+ 이 코드는 동시발생 행렬에 대해서만 PPMI 행렬을 구할 수 있고자 단순화해 구현했다.\n",
        "+ 구체적으로 단어 x,y가 동시에 발행하는 수를 C(x,y)라 했을 때, $C(x) = Σ_i C(i, x), C(y) = Σ_i C(i, y), N = Σ_iΣ_j C(i,j)$가 되도록 구현했다.\n",
        "+ np.log2(0)이 -inf가 되는 것을 피하기 위해 eps 작은 값을 사용하였다."
      ],
      "metadata": {
        "id": "IPLzHvZcfLc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 동시발생 행렬을 PPMI 행렬로 변환하는 것을 구현해보자."
      ],
      "metadata": {
        "id": "eMvX1v9GgDh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep-learning-from-scratch-2-master/')\n",
        "import numpy as np\n",
        "from common.util import preprocess, create_co_matrix, cos_similarity, ppmi\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "W = ppmi(C)\n",
        "\n",
        "np.set_printoptions(precision=3)  # 유효 자릿수를 세 자리로 표시\n",
        "print('동시발생 행렬')\n",
        "print(C)\n",
        "print('-'*50)\n",
        "print('PPMI')\n",
        "print(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh1AHNWSf0Rd",
        "outputId": "f1028edc-0ac1-4ea8-f637-2c7cbefa7efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "동시발생 행렬\n",
            "[[0 1 0 0 0 0 0]\n",
            " [1 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0]]\n",
            "--------------------------------------------------\n",
            "PPMI\n",
            "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.807 0.    0.    0.    0.    2.807]\n",
            " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 이상이 동시발생 행렬을 PPMI 행렬로 변환하는 방법이다.\n",
        "+ PPMI 행렬에도 여전히 큰 문제가 있는데 말뭉치의 어휘 수가 증가함에 따라 각 단어 벡터의 차원 수가 증가한다는 것이다.\n",
        "+ 행렬의 내용을 보면 대부분 원소가 0임을 알 수 있는데 이는 원소 대부분이 중요하지 않다는 똣이다.\n",
        "+ 이런 벡터는 노이즈에 약하고 견고하지 못하다는 약점이 존재한다.\n",
        "+ 이 문제에 대처하고자 수행하는 기법이 벡터의 차원 감소이다.\n"
      ],
      "metadata": {
        "id": "73HM5Ledggbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.2 차원 감소"
      ],
      "metadata": {
        "id": "fe0H8Wi1g8Ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 차원 감소는 벡터의 차원을 줄이는 방법이다.\n",
        "+ 단순히 줄이는 것이 아니라 중요한 정보는 유지하면서 줄인다.\n",
        "+ 아래 그림처럼 데이터의 분포를 고려해 중요한 축을 찾는 일을 수행한다."
      ],
      "metadata": {
        "id": "x2RCgBOPaK0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1urWQy6pR-rqnGQ0rBXoaeI46GBP0F283' width =550/><br>"
      ],
      "metadata": {
        "id": "f_Bvls1UaYAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 왼쪽은 데이터점들을 2차원 좌표에 표시한 것이다.\n",
        "+ 오른쪽은 새로운 축을 도입하여 같은 데이터를 좌표축 하나만으로 표시했다.  \n",
        "(새로운 축을 찾을 때는 데이터가 넓게 분포되도록 고려해야 한다.)\n",
        "+ 이때 각 데이터점의 값은 새로운 축으로 사영된 값으로 변한다.\n",
        "+ 중요한 것은 가장 적합한 축을 찾는 일로, 1차원 값만으로 데이터의 본질적 차이를 구별할 수 있어야 한다.\n",
        "+ 이런 작업은 다차원 데이터에서도 수행할 수 있다."
      ],
      "metadata": {
        "id": "uD_sI6dGa3N6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 차원 감소에는 여러 방법이 있지만 특잇값 분해(SVD)를 이용하자.\n",
        "+ SVD의 수식은 다음과 같다."
      ],
      "metadata": {
        "id": "qxvFQbUFcViE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1_cndGfu2pQ09vv7ukF4HWGtJLcATyTOf' width = 550/><br>"
      ],
      "metadata": {
        "id": "FdjkfSDDcqES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ SVD는 임의의 행렬 X를 U, S, V 세 행렬의 곱으로 분해한다.\n",
        "+ U,V는 직교행렬이고 이 행렬의 열벡터는 서로 직교한다. S는 대각행렬이다.\n",
        "+ 이 수식을 시각화하면 다음과 같다."
      ],
      "metadata": {
        "id": "XuiTcqLldXAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1npNDIfCOwnK5Li-46PrzzpERJjLkl5Fh' width =550 /><br>"
      ],
      "metadata": {
        "id": "qvs_-GlOd0Up"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ U는 직교행렬로 어떠한 공간의 축(기저)을 형성한다. 이 행렬을 단어 공간으로 취급할 수 있다.\n",
        "+ S는 대각행렬로 대각성분에는 특잇값이 큰 순서로 나열되어 있다.\n",
        "+ 특이값이란 해당 축의 중요도이다.\n",
        "+ 따라서 아래와 같이 중요도가 낮은 원소를 깎아내는 방법을 생각할 수 있다."
      ],
      "metadata": {
        "id": "-0VMsFg7d3eK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1llHaZ6c15kIgegc4V33z_FUoz302olyg' width = 550 /><br>"
      ],
      "metadata": {
        "id": "RGr9xi80eX13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ S에서 특잇값이 작다면 중요도가 낮다는 뜻으로 U에서 여분의 열벡터를 깍아내어 원래의 행렬을 근사할 수 있다.\n",
        "+ 이를 단어의 PPMI 행렬에 적용하자.\n",
        "+ X의 각 행에는 해당 단어 ID의 단어 벡터가 저장되어 있으며 이 단어 벡터가 U'라는 차원 감소된 벡터로 표현된다."
      ],
      "metadata": {
        "id": "sW9HrmMteZaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.3 SVD에 의한 차원 감소"
      ],
      "metadata": {
        "id": "qLP7cn7xlXWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ SVD를 파이썬 코드로 살펴보자. SVD는 넘파이의 linalg 모듈의 svd 메서드로 실행할 수 있다."
      ],
      "metadata": {
        "id": "zahgG7wflbYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep-learning-from-scratch-2-master/')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from common.util import preprocess, create_co_matrix, ppmi\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(id_to_word)\n",
        "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
        "W = ppmi(C)\n",
        "\n",
        "# SVD\n",
        "U, S, V = np.linalg.svd(W)"
      ],
      "metadata": {
        "id": "SIal5ISbgQDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ SVD에 의해 변환된 밀집벡터 표현은 U에 저장된다.\n",
        "+ 단어 ID가 0인 단어 벡터를 보자."
      ],
      "metadata": {
        "id": "cuVno44Fl5s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(C[0])\n",
        "print(W[0])\n",
        "print(U[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni-my6qNlyCx",
        "outputId": "5ceecdae-067f-49ff-ad20-55098ce263a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 0 0]\n",
            "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            "[ 3.409e-01 -1.110e-16 -1.205e-01 -4.163e-16 -9.323e-01 -1.110e-16\n",
            " -2.426e-17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 원래 희소벡터인 W[0]가 SVD에 의해 밀집벡터 U[0]로 변했다.\n",
        "+ 밀집벡터의 차원을 감소시키려면 예를 들어 2차원 벡터로 줄이려면 단순히 처움 두 원소를 꺼내면 된다."
      ],
      "metadata": {
        "id": "bQusTm37n0Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(U[0,:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkAjBPoin_nZ",
        "outputId": "2a1ad873-65a2-4485-b908-7a3c7d3fcf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3.409e-01 -1.110e-16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 각 단어를 2차원 벡터로 표현한 후 그래프로 그려보자. 다음 코드를 추가하면 된다."
      ],
      "metadata": {
        "id": "8OWt2ubLoSTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word, word_id in  word_to_id.items():\n",
        "  # 2차원 그래프상에서 좌표 (x,y) 지점에 word에 담긴 텍스트를 그린다.\n",
        "  plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
        "\n",
        "plt.scatter(U[:,0], U[:, 1], alpha = 0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Elq_XkL6oDI6",
        "outputId": "bf307ba2-55e6-4faa-801d-9366e3a32ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 위 그래프를 보면 goodbye, hello, you와 i가 제법 가까이 있음을 알 수 있다.\n",
        "+ 우리의 직관과는 비슷하지만 말뭉치의 크기가 작아서 그대로 받아들이기에 충분하지 않다.\n",
        "+ PTB 데이터셋이라는 큰 말뭉치를 사용하여 실험을 수행해보자."
      ],
      "metadata": {
        "id": "qlY2zRZep9eX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.4 PTB 데이터셋"
      ],
      "metadata": {
        "id": "285nbsdaq4Zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ PTB 말뭉치는 word2vec의 발명자인 토마스 미콜로프의 웹 페이지에서 받을 수 있다.\n",
        "+ 텍스트 파일로 제공되며, PTB 문장에 몇가지 전처리를 해두었다.\n",
        "+ 아래 그림은 PTB 말뭉치의 내용을 보여준다."
      ],
      "metadata": {
        "id": "kAgoNk9zq8qG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://drive.google.com/uc?export=view&id=1zofwagqD7mkwInkamMBw-v6uw_jJ3WxY' width = 550/><br>"
      ],
      "metadata": {
        "id": "NJ5Q1Y_trT0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ PTB 말뭉치는 한 문장이 하나의 줄로 저장되어 있다.\n",
        "+ 여기서는 각 문장을 연결한 하나의 큰 시계열 데이터로 취급하고 각 문장 끝에 <eos>라는 특수문자를 삽입한다.\n",
        "+ PTB 데이터셋을 쉽게 이용할 수 있도록하는 파이썬 코드가 준비되어있다."
      ],
      "metadata": {
        "id": "-68cD3TcrXdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep-learning-from-scratch-2-master/')\n",
        "from dataset import ptb\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "\n",
        "print('말뭉치 크기:', len(corpus))\n",
        "print('corpus[:30]:', corpus[:30])\n",
        "print()\n",
        "print('id_to_word[0]:', id_to_word[0])\n",
        "print('id_to_word[1]:', id_to_word[1])\n",
        "print('id_to_word[2]:', id_to_word[2])\n",
        "print()\n",
        "print(\"word_to_id['car']:\", word_to_id['car'])\n",
        "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
        "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi3BD8Zkonir",
        "outputId": "1873ea53-903f-4470-f1f8-ca5a93dbeea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ptb.train.txt ... \n",
            "Done\n",
            "말뭉치 크기: 929589\n",
            "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "id_to_word[0]: aer\n",
            "id_to_word[1]: banknote\n",
            "id_to_word[2]: berlitz\n",
            "\n",
            "word_to_id['car']: 3856\n",
            "word_to_id['happy']: 4428\n",
            "word_to_id['lexus']: 7426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "corpus에는 단어 ID 목록이 저장된다.  \n",
        "id_to_word : 단어 ID에서 단어로 변환하는 딕셔너리  \n",
        "word_to_id : 단어에서 단어로 변환하는 딕셔너리이다."
      ],
      "metadata": {
        "id": "WP21XvPLsOwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ ptb.load_data()는 데이터를 읽어 들인다.\n",
        "+ 인수로 train, test, valid 중 하나를 지정할 수 있는데 이는 훈련용, 테스트용, 검증용 데이터를 가리킨다."
      ],
      "metadata": {
        "id": "BD4UR4dvsjaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.5 PTB 데이터셋 평가"
      ],
      "metadata": {
        "id": "jPa57wofsvfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ PTB 데이터셋에 통계 기반 기법에 적용하자.\n",
        "+ 간단한 SVD도 사용할 수 있지만 시간이 오래걸리고 메모리도 많이 사용한다.\n",
        "+ 이번에는 큰 행렬에 SVD를 적용하므로 고속 SVD를 이용한다.\n",
        "+ 코드는 다음과 같다."
      ],
      "metadata": {
        "id": "rwd7Ypaysxxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep-learning-from-scratch-2-master/')\n",
        "import numpy as np\n",
        "from common.util import most_similar, create_co_matrix, ppmi\n",
        "from dataset import ptb\n",
        "\n",
        "window_size = 2\n",
        "wordvec_size = 100\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "print('동시발생 수 계산 ...')\n",
        "C = create_co_matrix(corpus, vocab_size, window_size)\n",
        "print('PPMI 계산 ...')\n",
        "W = ppmi(C, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deYze-d3rzuY",
        "outputId": "71e7df23-3186-434e-cbd2-1aad24b78bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "동시발생 수 계산 ...\n",
            "PPMI 계산 ...\n",
            "1.0% 완료\n",
            "2.0% 완료\n",
            "3.0% 완료\n",
            "4.0% 완료\n",
            "5.0% 완료\n",
            "6.0% 완료\n",
            "7.0% 완료\n",
            "8.0% 완료\n",
            "9.0% 완료\n",
            "10.0% 완료\n",
            "11.0% 완료\n",
            "12.0% 완료\n",
            "13.0% 완료\n",
            "14.0% 완료\n",
            "15.0% 완료\n",
            "16.0% 완료\n",
            "17.0% 완료\n",
            "18.0% 완료\n",
            "19.0% 완료\n",
            "20.0% 완료\n",
            "21.0% 완료\n",
            "22.0% 완료\n",
            "23.0% 완료\n",
            "24.0% 완료\n",
            "25.0% 완료\n",
            "26.0% 완료\n",
            "27.0% 완료\n",
            "28.0% 완료\n",
            "29.0% 완료\n",
            "30.0% 완료\n",
            "31.0% 완료\n",
            "32.0% 완료\n",
            "33.0% 완료\n",
            "34.0% 완료\n",
            "35.0% 완료\n",
            "36.0% 완료\n",
            "37.0% 완료\n",
            "38.0% 완료\n",
            "39.0% 완료\n",
            "40.0% 완료\n",
            "41.0% 완료\n",
            "42.0% 완료\n",
            "43.0% 완료\n",
            "44.0% 완료\n",
            "45.0% 완료\n",
            "46.0% 완료\n",
            "47.0% 완료\n",
            "48.0% 완료\n",
            "49.0% 완료\n",
            "50.0% 완료\n",
            "51.0% 완료\n",
            "52.0% 완료\n",
            "53.0% 완료\n",
            "54.0% 완료\n",
            "55.0% 완료\n",
            "56.0% 완료\n",
            "57.0% 완료\n",
            "58.0% 완료\n",
            "59.0% 완료\n",
            "60.0% 완료\n",
            "61.0% 완료\n",
            "62.0% 완료\n",
            "63.0% 완료\n",
            "64.0% 완료\n",
            "65.0% 완료\n",
            "66.0% 완료\n",
            "67.0% 완료\n",
            "68.0% 완료\n",
            "69.0% 완료\n",
            "70.0% 완료\n",
            "71.0% 완료\n",
            "72.0% 완료\n",
            "73.0% 완료\n",
            "74.0% 완료\n",
            "75.0% 완료\n",
            "76.0% 완료\n",
            "77.0% 완료\n",
            "78.0% 완료\n",
            "79.0% 완료\n",
            "80.0% 완료\n",
            "81.0% 완료\n",
            "82.0% 완료\n",
            "83.0% 완료\n",
            "84.0% 완료\n",
            "85.0% 완료\n",
            "86.0% 완료\n",
            "87.0% 완료\n",
            "88.0% 완료\n",
            "89.0% 완료\n",
            "90.0% 완료\n",
            "91.0% 완료\n",
            "92.0% 완료\n",
            "93.0% 완료\n",
            "94.0% 완료\n",
            "95.0% 완료\n",
            "96.0% 완료\n",
            "97.0% 완료\n",
            "98.0% 완료\n",
            "99.0% 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('calculating SVD ...')\n",
        "try:\n",
        "    # truncated SVD (빠르다!)\n",
        "    from sklearn.utils.extmath import randomized_svd\n",
        "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
        "                             random_state=None)\n",
        "except ImportError:\n",
        "    # SVD (느리다)\n",
        "    U, S, V = np.linalg.svd(W)\n",
        "\n",
        "word_vecs = U[:, :wordvec_size]\n",
        "\n",
        "querys = ['you', 'year', 'car', 'toyota']\n",
        "for query in querys:\n",
        "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKAL0b_wsky",
        "outputId": "41d0892a-e91a-4f97-9a1d-5ab076c42f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculating SVD ...\n",
            "\n",
            "[query] you\n",
            " i: 0.7467241883277893\n",
            " do: 0.6105207800865173\n",
            " we: 0.6018752455711365\n",
            " else: 0.5320366621017456\n",
            " anybody: 0.517670214176178\n",
            "\n",
            "[query] year\n",
            " month: 0.6848497986793518\n",
            " last: 0.6223364472389221\n",
            " quarter: 0.6118013858795166\n",
            " earlier: 0.6028626561164856\n",
            " next: 0.5908927321434021\n",
            "\n",
            "[query] car\n",
            " auto: 0.6635012626647949\n",
            " luxury: 0.6165549159049988\n",
            " cars: 0.598263144493103\n",
            " truck: 0.5516860485076904\n",
            " corsica: 0.4919765293598175\n",
            "\n",
            "[query] toyota\n",
            " motor: 0.7425025701522827\n",
            " motors: 0.6562225222587585\n",
            " nissan: 0.6451542377471924\n",
            " lexus: 0.6401390433311462\n",
            " honda: 0.6144697070121765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ SVD를 수행할 때 sklearn의 randomized_svd() 메서드를 이용한다.\n",
        "+ 이 메서드는 무작위를 사용한 Truncated SVD로 특잇값이 큰 것들만 계산하여 기본적인 SVD보다 훨씬 빠르다."
      ],
      "metadata": {
        "id": "adh2rO_MtpIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ __Truncated SVD는 무작위 수를 사용하므로 결과가 매번 다르다.__\n",
        "+ 실행 결과를 보면 you라는 검색어에서는 i, do, we가 상위를 차지했음을 알 수 있다.\n",
        "+ year의 연관어로는 month,last, quarter이, car의 연관어로는 auto, luxury, cars 등이 뽑혔다.\n",
        "+ toyota와 관련된 단어로 motor, nissan, lexus 등이 뽑혔다.\n",
        "+ 이처럼 단어의 의미나 문법적인 관점에서 비슷한 단어들이 가까운 벡터로 나타났다."
      ],
      "metadata": {
        "id": "spfPIOF1uLPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ 지금까지 단어의 의미를 벡터로 인코딩하는 데 성공했다.\n",
        "+ 말뭉치를 사용해 맥락에 속한 단어의 등장 횟수를 센 후 PPMI 행렬로 변환하고, 다시 SVD를 이용해 차원을 감소시킴으로써 더 좋은 단어 벡터를 얻었다.\n",
        "+ 이것이 단어의 분산 표현이고, 각 단어는 고정 길이의 밀집 벡터로 표현되었다."
      ],
      "metadata": {
        "id": "vHIPUpGhujjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 정리"
      ],
      "metadata": {
        "id": "AzatTwh_u1fP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ WordNet 등의 시소러스를 이용하면 유의어를 얻거나 단어 사이의 유사도를 측정하는 등 유용한 작업을 할 수 있다.\n",
        "+ 시소러스 기반 기법은 시소러스를 작성하는 데 많은 인적 자원이 든다거나 새로운 단어에 대응하기 어렵다는 문제가 있다.\n",
        "+ 현재는 말뭉치를 이용해 단어를 벡터화하는 방식이 주로 쓰인다.\n",
        "+ 최근의 단어 벡터화 기법들은 대부분 단어의 의미는 주변 단어에 의해 형성된다는 분포 가설에 기초한다.\n",
        "+ 통계 기반 기법은 말뭉치 안의 각 단어에 대해서 그 단어의 주변 단어의 빈도를 집계한다.(동시발생 행렬)\n",
        "+ 동시발생 행렬을 PPMI 행렬로 변환하고 다시 차원을 감소시킴으로써 거대한 희소벡터를 작은 밀집벡터로 변환할 수 있다.\n",
        "+ 단어의 벡터 공간에서는 의미가 가까운 단어는 그 거리도 가까울 것으로 기대한다."
      ],
      "metadata": {
        "id": "gYJ9wr0mu3dZ"
      }
    }
  ]
}